Sono detti dati sintetici i dati generati da un software. La necessità di avere dati sintetici non nasce dalla mancanza di dati, bensì dal fatto che questi siano detenuti da poche grandi potenze che, grazie all'enorme bacino di utenti da cui traggono questi dati, continuano ad accumularne rendendoli spesso disponibili solo su pagamento, tagliando di fatto fuori le compagnie più piccole che trovano nei dati sintetici una manna, non avendo né le disponibilità economiche né i bacini di utenza adatti a raccogliere veri dati. Un altro fattore che stimola la necessità di dati sintetici è la privacy: questa è infatti inesistente su dati che non esistono.
Ci sono, inoltre, situazioni in cui i dati reali non sono un'opzione in primo luogo (es. training frenata intelligente in prossimità di strisce pedonali su cui transita un pedone).

La keypoint detection consiste nello stimare quali sono i punti salienti di un'immagine. Questa stima passa da una serie di procedure definite all'interno di uno specifico modello, che va allenato e necessità dunque di una grossa mole di dati: ci vengono incontro, in questa fase, i dati sintetici. 
I dati sintetici utilizzati per trainare la keypoint detection, se generati in appositi ambienti (es. Unreal Engine), sono già labellati durante il render e, da qui, impiegabili per il training. 
La keypoint detection può essere utilizzata, ad esempio, per estrarre le feature facciali di un soggetto ritratto in un'immagine oppure può essere utilizzata su ogni frame di un video ritraente una strada affollata per seguire l'andamento dello scheletro dei passanti.

Una Convolutional Neural Network è una rete neurale artificiale con l'abilità di riconoscere pattern (feature) all'interno di immagini, ed è quindi utilizzata per l'identificazione degli elementi in esse contenuti.
I layer interni (hidden layers) sono convolutional layer e ognuno di essi ha filtri specifici, progettati appositamente per estrarre una determinata feature dall'immagine. I primi layer avranno filtri che puntano a estrarre elementi semplici (bordi, spigoli), mentre andando avanti si arriverà, ad esempio, a ricercare un cane all'interno della figura.

Al giorno d'oggi, l'object detection consiste nel labeling e nella segmentazione di ogni singolo pixel all'interno dell'immagine - questa procedura è detta panoptic segmentation e richiede un grosso lavoro da parte della CNN per poter avere successo, data la mole di feature (da estrarre) necessaria.
Detectron2 è un'evoluzione lineare di Detectron e fornisce un ambiente personalizzabile per qualsiasi tipo di object detection.

POSSIBILI APPROFONDIMENTI (da sistemare):
Opzioni per generare dati sintetici:
- SMOTE (Synthetic Minority Over-sampling TEchnique): utile in problemi di classificazione con dataset "imbalanced" (es. un dataset con sole due classi in cui una classe è significativamente più popolata dell'altra), che non rendono possibile un machine learning di qualità. Prende un dato dalla classe meno popolata, ne osserva la neighbourhood possibile e la va a popolare con dati sintetici. Lo SMOTE% indica quante istanze si vanno a generare per ogni istanza della classe minoritaria (es. 600% = 6 istanze generate per 1 istanza presente => da n istanze di partenza ho 7n istanze di arrivo).

- ADASYN (ADAptive SYNthetic sampling method): supponiamo di avere 5 classi, di cui 3 di minoranza, 2 delle quali siamo riusciti a far imparare alla macchina senza problemi. Andiamo quindi a generare esempi della rimanente classe di minoranza basandoci sui dati delle altre 2 classi di minoranza. Una classe facile da imparare avrà dunque associato un dataset meno pesante rispetto a quello di una classe di difficile apprendimento (quest'ultimo sarà infatti stato ampliato dall'algoritmo)

- Data Augmentation: utile quando bisogna classificare immagini. Prendiamo ad esempio la classificazione binaria cane vs gatto con dataset di piccole dimensioni a nostra disposizone: possiamo ampliare questi dataset zoomando le immagini, ruotandole, cambiando il gradiente ecc.. di modo da avere "cibo" per far crescere il modello;

- Variational Auto Encoder: genera dati realizzando con gli input una distribuzione gaussiana (si perderà un po'di qualità perché vanno fittati per rispettare questo tipo di distribuzione) (RIGUARDARE)

- Cut & Paste: per dataset di immagini, si generano nuove immagini prendendo ad esempio l'oggetto che ci interessa in foreground da un'immagine sfruttando una segmentation mask e ponendolo sul background fornito da un'altra immagine con un po' di blending. A noi il background non interessa, dobbiamo insegnare all'algoritmo a ignorarlo concentrandosi solo sull'oggetto. Non si prende in considerazione (ed è un limite) la geometria del background;

- Synthetic Data for Text Localization in Neutral Images: prima si usa un algoritmo di contour detection su un'immagine di background, si selezionano le regioni più ampie e si fa una mappa di profondità sfruttando una CNN. A questo punto si seleziona una "facet" (faccetta) di tale regione con l'algoritmo Ransac e si inserisce il testo all'interno di essa seguendo le indicazioni fornite dall'analisi della profondità e dalla prospettiva (ruotare ecc). Ovviamente durante l'applicazione della scritta si fa del blending di modo da far sembrare il tutto naturale.

- GAN (Generative Adversarial Network): si parte da due modelli, un discriminator (decidere quale immagine è vera e quale è falsa) e un generator (crea nuove immagini che sembrano l'immagine di input). Lasciandoli lavorare entrambi diventano bravi nel loro lavoro e abbiamo dunque due modelli.